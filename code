``` python
# 1. Import necessary libraries
# -------------------------------------- CELL 1 STARTS HERE --------------------------------------
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import statsmodels.api as sm  # To add the regression summary

# 2. Load the dataset
data = pd.read_csv('/Users/jcvalverde/Desktop/Updated_Employee_Turnover_Dataset.csv')

# 3. Display the first 5 rows of the dataset
print("Dataset Sample:")
print(data.head())
# -------------------------------------- CELL 1 ENDS HERE --------------------------------------


# 4. Define feature variables and target variable
# -------------------------------------- CELL 2 STARTS HERE --------------------------------------
X = data[['age', 'tenure', 'salary', 'performance_score', 'engagement_score', 'department', 'avg_performance', 
          'years_since_last_promotion', 'performance_improvement', 'salary_per_performance']]
y = data['turnover']  # Target variable (1 for turnover, 0 for stayed)

# 5. Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 6. Add a constant column for the intercept in statsmodels
X_train_with_intercept = sm.add_constant(X_train)

# 7. Train the logistic regression model using statsmodels
logit_model = sm.Logit(y_train, X_train_with_intercept)
result = logit_model.fit()

# 8. Print the full summary of the regression
print("\nLogistic Regression Summary using Statsmodels:")
print(result.summary())

# 9. Display the coefficients with variable names (in statsmodels)
print("\nModel Coefficients from Statsmodels:")
coef_summary = pd.DataFrame({
    'Feature': ['const'] + X.columns.tolist(),
    'Coefficient': result.params.values
})
print(coef_summary)
# -------------------------------------- CELL 2 ENDS HERE --------------------------------------


# 10. Train the logistic regression model using scikit-learn
# -------------------------------------- CELL 3 STARTS HERE --------------------------------------
# Scale the data (fit on training data and transform both training and test data)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform on training data
X_test_scaled = scaler.transform(X_test)        # Transform test data

# Train the logistic regression model using scikit-learn
model = LogisticRegression(max_iter=200)
model.fit(X_train_scaled, y_train)

# Presenting the Logistic Regression Summary using Statsmodels
print("\nLogistic Regression Summary using Statsmodels (Training Set):")
print(result.summary())

# Display coefficients from Statsmodels again for convenience
coef_summary = pd.DataFrame({
    'Feature': ['const'] + X.columns.tolist(),
    'Coefficient': result.params.values
})
print("\nModel Coefficients from Statsmodels:")
print(coef_summary)
# -------------------------------------- CELL 3 ENDS HERE --------------------------------------


# 11. Make predictions and evaluate the model
# -------------------------------------- CELL 4 STARTS HERE --------------------------------------
# Make predictions on the test set
y_pred = model.predict(X_test_scaled)  # Predicted class labels
y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]  # Predicted probabilities for the positive class

# Evaluate the model
print("\nModel Evaluation Metrics:")

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

# Precision, Recall, F1-Score (Classification Report)
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# AUC and ROC Curve
auc = roc_auc_score(y_test, y_pred_prob)
print(f"\nAUC: {auc:.4f}")

# Plot ROC curve
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.figure()
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.4f})')
plt.plot([0, 1], [0, 1], color="navy", linestyle="--")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()
# -------------------------------------- CELL 4 ENDS HERE --------------------------------------


# 12. Present final model coefficients using scikit-learn
# -------------------------------------- CELL 5 STARTS HERE --------------------------------------
# Get the final model coefficients using scikit-learn
coefficients = model.coef_[0]  # Coefficients for the logistic regression model
intercept = model.intercept_   # Intercept (bias term)

# Create a DataFrame to display the final model coefficients with the original feature names
feature_names = X.columns  # Get the column names from the dataset
coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': coefficients
})

# Display the DataFrame with variable names and their respective coefficients in the final model
print("\nFinal Model Coefficients and Intercept from Scikit-learn:")
print(f"Intercept: {intercept[0]:.4f}")
print(coef_df)
# -------------------------------------- CELL 5 ENDS HERE --------------------------------------
```
